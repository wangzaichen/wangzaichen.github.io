<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小车苏喂</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-06-30T08:23:31.936Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>feature map 计算方法</title>
    <link href="http://example.com/2021/06/30/featuremap/"/>
    <id>http://example.com/2021/06/30/featuremap/</id>
    <published>2021-06-30T08:22:51.858Z</published>
    <updated>2021-06-30T08:23:31.936Z</updated>
    
    <content type="html"><![CDATA[<h2 id="feature-map-计算方法"><a href="#feature-map-计算方法" class="headerlink" title="feature map 计算方法"></a>feature map 计算方法</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">卷积层的feature map的变长为：conv1_h=（32-5）/1 + 1 = 28 </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;feature-map-计算方法&quot;&gt;&lt;a href=&quot;#feature-map-计算方法&quot; class=&quot;headerlink&quot; title=&quot;feature map 计算方法&quot;&gt;&lt;/a&gt;feature map 计算方法&lt;/h2&gt;&lt;figure class=&quot;hi</summary>
      
    
    
    
    <category term="Diary" scheme="http://example.com/categories/Diary/"/>
    
    
    <category term="PS3" scheme="http://example.com/tags/PS3/"/>
    
    <category term="Games" scheme="http://example.com/tags/Games/"/>
    
  </entry>
  
  <entry>
    <title>损失函数目标函数</title>
    <link href="http://example.com/2021/06/30/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0/"/>
    <id>http://example.com/2021/06/30/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0/</id>
    <published>2021-06-30T06:46:13.000Z</published>
    <updated>2021-06-30T08:10:49.661Z</updated>
    
    <content type="html"><![CDATA[<p>损失函数==代价函数</p><span id="more"></span><h1 id="损失函数-代价函数"><a href="#损失函数-代价函数" class="headerlink" title="损失函数==代价函数"></a>损失函数==代价函数</h1><p>首先给出结论：损失函数和代价函数是同个东西，目标函数是一个与他们相关但更广的概念，对于目标函数来说在有约束条件下的最小化就是损失函数（ loss function）</p><p>（图片来自 Andrew Ng Machine Learning公开课视频）<br><img src="https://pic4.zhimg.com/80/v2-3f4959cd70308df496ecc4568a0d982d_720w.jpg?source=1940ef5c" alt="avatar"></p><p>上面三个图的函数依次为f1（x），f2（x），f3（x）。我们是想用这三个函数分别来拟合Pce Pice的真实值记为Y我们给定c，这三个函数都会输出一个∫（X）这个输出的∫（X）与真实值Y可能是相同的，也可能是不同的，为了表示我们拟合的好坏，我们就用—个函数来度量拟合的程度，比如L（Y,f（X）=（Y-f（X）^2，这个函数就称为损失函数（ loss function），或者叫代价函数（ cost function）。损失函数越小，就代表模型拟合的越好那是不是我们的目标就只是让 loss function越小越好呢？还不是.</p><p>另一个概念 <strong>风险函数</strong>。 他是损失函数的期望。我们的输入输出是一个（X,Y）尊崇联合分布，一个函数的平均损失称作（经验风险）即，<br>$\frac { 1 } { N } \sum _ { i = 1 } ^ { N } L ( y _ { i } , {f ( x _ { i } )} )$  所以我们的目标是最小化<br>$\frac { 1 } { N } \sum _ { i = 1 } ^ { N } L ( y _ { i } , {f ( x _ { i } )} )$ </p><p>我们称之为<em><strong>经验风险最小化</strong></em></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;损失函数==代价函数&lt;/p&gt;</summary>
    
    
    
    <category term="Diary" scheme="http://example.com/categories/Diary/"/>
    
    
  </entry>
  
  <entry>
    <title>卷积和反卷积</title>
    <link href="http://example.com/2021/06/08/%E5%8D%B7%E7%A7%AF%E5%8F%8D%E5%8D%B7%E7%A7%AF/"/>
    <id>http://example.com/2021/06/08/%E5%8D%B7%E7%A7%AF%E5%8F%8D%E5%8D%B7%E7%A7%AF/</id>
    <published>2021-06-08T01:31:57.201Z</published>
    <updated>2021-06-30T08:14:55.303Z</updated>
    
    <content type="html"><![CDATA[<p>卷积反卷积计算方法</p><span id="more"></span><p>正文</p><h2 id="什么是-反卷积"><a href="#什么是-反卷积" class="headerlink" title="什么是 反卷积"></a>什么是 反卷积</h2><h3 id="上采样（Upsample）"><a href="#上采样（Upsample）" class="headerlink" title="上采样（Upsample）"></a>上采样（Upsample）</h3><p> 计算机视觉 深度学习领域， 由于输入图像通过卷积神经网络（CNN）提取特征后<br>  输出尺寸往往会变小，而有时我们需要将图像恢复到原来尺寸<br>  扩大图像尺寸，实现图像由小分辨率到大分辨率的映射操作 即叫做上采样（Upsample）</p><h3 id="反卷积（Transfer-Convloution）"><a href="#反卷积（Transfer-Convloution）" class="headerlink" title="反卷积（Transfer Convloution）"></a>反卷积（Transfer Convloution）</h3><p>  上采样有3种常见的方法：双线性插值（ bilinear），反卷积（ Transposed Convolution），反池化Unpooling），我们这里只讨论反卷积。这里指的反卷积，也叫转置卷积，它并不是正向卷积的完全逆过程，用一句话来解释：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">反卷积是种特殊的正向卷积，先按照定的比例通过补0来扩大输入图像的尺寸，</span><br><span class="line">接看旋转卷积核，再进行正向卷积。</span><br></pre></td></tr></table></figure><hr><h2 id="反卷积的数学推导"><a href="#反卷积的数学推导" class="headerlink" title="反卷积的数学推导"></a>反卷积的数学推导</h2><p>输入图像 $input$ 尺寸$4 \times 4$ 元素矩阵为：<br>$$<br>\text { input }=\left[\begin{array}{cccc}<br>x_{1} &amp; x_{2} &amp; x_{3} &amp; x_{4} \<br>x_{5} &amp; x_{6} &amp; x_{7} &amp; x_{8} \<br>x_{9} &amp; x_{10} &amp; x_{11} &amp; x_{12} \<br>x_{13} &amp; x_{14} &amp; x_{15} &amp; x_{16}<br>\end{array}\right]<br>$$<br>卷积核 $kernel$ 尺寸是 $3\times3$</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;卷积反卷积计算方法&lt;/p&gt;</summary>
    
    
    
    <category term="Diary" scheme="http://example.com/categories/Diary/"/>
    
    
    <category term="PS3" scheme="http://example.com/tags/PS3/"/>
    
    <category term="Games" scheme="http://example.com/tags/Games/"/>
    
  </entry>
  
</feed>
